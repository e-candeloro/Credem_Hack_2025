{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MATCHING SUMMARY ===\n",
      "Total rows analyzed: 63\n",
      "Total possible matches (rows × 3 fields): 189\n",
      "Total actual matches found: 57\n",
      "Total valid fields (with data): 185\n",
      "\n",
      "MATCH RATES:\n",
      "  Against all possible (matches/rows×3): 30.16%\n",
      "  Against valid fields only: 30.81%\n",
      "\n",
      "FIELD BREAKDOWN:\n",
      "  First Names: 1/62 matched\n",
      "  Last Names: 1/62 matched\n",
      "  Dates: 55/61 matched\n",
      "\n",
      "SCORE: 57/189 (30.2%)\n",
      "\n",
      "Detailed Results:\n",
      "              CSV_Name  First_Name_Matches  Last_Name_Matches  Date_Matches  \\\n",
      "0       Sassi Maurizio                   0                  0             1   \n",
      "1   Paltrinieri Silvia                   0                  0             1   \n",
      "2       Cioni Giuseppe                   0                  0             1   \n",
      "3         Poppi Andrea                   0                  0             1   \n",
      "4   Ficarazzo Riccardo                   0                  0             1   \n",
      "..                 ...                 ...                ...           ...   \n",
      "58       Busi Leonardo                   0                  0             2   \n",
      "59    Felloni Federica                   0                  0             1   \n",
      "60  Ficarazzo Riccardo                   0                  0             1   \n",
      "61      Polito Alessio                   0                  0             1   \n",
      "62      Lalli Gianluca                   0                  0             1   \n",
      "\n",
      "    Full_Matches  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "..           ...  \n",
      "58             0  \n",
      "59             0  \n",
      "60             0  \n",
      "61             0  \n",
      "62             0  \n",
      "\n",
      "[63 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import Tuple, List\n",
    "import re\n",
    "from datetime import datetime\n",
    "import io\n",
    "\n",
    "def read_bat_file(file_path: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Reads a .bat file containing structured data and returns two pandas DataFrames.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the .bat file\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame]: \n",
    "            - First DataFrame: DocumentsOfRecord records\n",
    "            - Second DataFrame: DocumentAttachment records\n",
    "    \"\"\"\n",
    "    \n",
    "    def parse_line(line: str) -> List[str]:\n",
    "        \"\"\"Parse a pipe-separated line into fields\"\"\"\n",
    "        return [field.strip() for field in line.split('|')]\n",
    "    \n",
    "    def process_records(lines: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Convert list of record lines into a DataFrame\"\"\"\n",
    "        if not lines:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # First line is the header\n",
    "        headers = parse_line(lines[0])\n",
    "        \n",
    "        # Remaining lines are data\n",
    "        data_rows = []\n",
    "        for line in lines[1:]:\n",
    "            if line.strip():  # Skip empty lines\n",
    "                row_data = parse_line(line)\n",
    "                # Ensure row has same number of columns as headers\n",
    "                while len(row_data) < len(headers):\n",
    "                    row_data.append('')\n",
    "                data_rows.append(row_data[:len(headers)])  # Truncate if too long\n",
    "        \n",
    "        return pd.DataFrame(data_rows, columns=headers)\n",
    "    \n",
    "    # Read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Clean lines (remove newlines and empty lines)\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "    \n",
    "    # Group lines by record type\n",
    "    record_groups = {}\n",
    "    current_type = None\n",
    "    current_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        # Check if this is a header line (starts with FILENAME|METADATA)\n",
    "        if line.startswith('FILENAME|METADATA|'):\n",
    "            # Save previous group if exists\n",
    "            if current_type and current_lines:\n",
    "                record_groups[current_type] = process_records(current_lines)\n",
    "            \n",
    "            # Start new group\n",
    "            parts = parse_line(line)\n",
    "            if len(parts) > 2:\n",
    "                current_type = parts[2]  # DocumentsOfRecord or DocumentAttachment\n",
    "                current_lines = [line]\n",
    "        else:\n",
    "            # This is a data line\n",
    "            if current_type:\n",
    "                current_lines.append(line)\n",
    "    \n",
    "    # Don't forget the last group\n",
    "    if current_type and current_lines:\n",
    "        record_groups[current_type] = process_records(current_lines)\n",
    "    \n",
    "    # Return the two DataFrames as a tuple\n",
    "    documents_of_record_df = record_groups.get('DocumentsOfRecord', pd.DataFrame())\n",
    "    document_attachment_df = record_groups.get('DocumentAttachment', pd.DataFrame())\n",
    "    \n",
    "    return documents_of_record_df, document_attachment_df\n",
    "\n",
    "def normalize_name(name: str) -> str:\n",
    "    \"\"\"Normalize name for comparison - handle case and spacing\"\"\"\n",
    "    if pd.isna(name) or name == '' or str(name).upper() == 'NESSUN DIPENDENTE':\n",
    "        return ''\n",
    "    return str(name).strip().upper()\n",
    "\n",
    "def normalize_date(date_str: str) -> str:\n",
    "    \"\"\"Normalize date string for comparison\"\"\"\n",
    "    if pd.isna(date_str) or date_str == '' or str(date_str).upper() == 'NESSUNA DATA':\n",
    "        return ''\n",
    "    \n",
    "    # Remove any extra whitespace\n",
    "    date_str = str(date_str).strip()\n",
    "    \n",
    "    # Handle different date formats\n",
    "    date_patterns = [\n",
    "        r'(\\d{1,2})/(\\d{1,2})/(\\d{4})',  # DD/MM/YYYY or D/M/YYYY\n",
    "        r'(\\d{4})/(\\d{1,2})/(\\d{1,2})',  # YYYY/MM/DD or YYYY/M/D\n",
    "        r'(\\d{4})-(\\d{1,2})-(\\d{1,2})',  # YYYY-MM-DD\n",
    "    ]\n",
    "    \n",
    "    for pattern in date_patterns:\n",
    "        match = re.search(pattern, date_str)\n",
    "        if match:\n",
    "            if pattern == date_patterns[0]:  # DD/MM/YYYY format\n",
    "                day, month, year = match.groups()\n",
    "                return f\"{int(day):02d}/{int(month):02d}/{year}\"\n",
    "            elif pattern == date_patterns[1]:  # YYYY/MM/DD format\n",
    "                year, month, day = match.groups()\n",
    "                return f\"{int(day):02d}/{int(month):02d}/{year}\"\n",
    "            elif pattern == date_patterns[2]:  # YYYY-MM-DD format\n",
    "                year, month, day = match.groups()\n",
    "                return f\"{int(day):02d}/{int(month):02d}/{year}\"\n",
    "    \n",
    "    return date_str.upper()\n",
    "\n",
    "def extract_name_parts(full_name: str) -> Tuple[str, str]:\n",
    "    \"\"\"Extract first name and last name from full name (FIRST_NAME LAST_NAME format)\"\"\"\n",
    "    if pd.isna(full_name) or full_name == '' or str(full_name).upper() == 'NESSUN DIPENDENTE':\n",
    "        return '', ''\n",
    "    \n",
    "    # Convert to uppercase and split\n",
    "    full_name_upper = str(full_name).strip().upper()\n",
    "    parts = full_name_upper.split()\n",
    "    \n",
    "    if len(parts) >= 2:\n",
    "        # Format is FIRST_NAME LAST_NAME\n",
    "        first_name = parts[0]  # First part is first name\n",
    "        last_name = ' '.join(parts[1:])  # Rest is last name\n",
    "        return first_name, last_name\n",
    "    elif len(parts) == 1:\n",
    "        # Only one name - treat as first name\n",
    "        return parts[0], ''\n",
    "    else:\n",
    "        return '', ''\n",
    "\n",
    "def compare_dataframes(bat_file_path: str, csv_data) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compare BAT file data with CSV data and count exact matches\n",
    "    \n",
    "    Args:\n",
    "        bat_file_path (str): Path to the BAT file\n",
    "        csv_data: Either a string (tab-separated CSV data) or a pandas DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Comparison results with match counts\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read BAT file\n",
    "    documents_df, attachments_df = read_bat_file(bat_file_path)\n",
    "    \n",
    "    # Combine both DataFrames from BAT file\n",
    "    bat_records = []\n",
    "    \n",
    "    # Add DocumentsOfRecord entries\n",
    "    if not documents_df.empty and 'DocumentName' in documents_df.columns:\n",
    "        for _, row in documents_df.iterrows():\n",
    "            bat_records.append({\n",
    "                'filename': row.get('FILENAME', ''),\n",
    "                'full_name': row.get('DocumentName', ''),\n",
    "                'date': row.get('DateFrom', ''),\n",
    "                'source': 'DocumentsOfRecord'\n",
    "            })\n",
    "    \n",
    "    # Add DocumentAttachment entries if they have name info\n",
    "    if not attachments_df.empty and 'Title' in attachments_df.columns:\n",
    "        for _, row in attachments_df.iterrows():\n",
    "            # Try to extract name from Title or other fields\n",
    "            title = row.get('Title', '')\n",
    "            if title and title != row.get('FILENAME', ''):\n",
    "                bat_records.append({\n",
    "                    'filename': row.get('FILENAME', ''),\n",
    "                    'full_name': title,\n",
    "                    'date': '',  # Attachments might not have dates\n",
    "                    'source': 'DocumentAttachment'\n",
    "                })\n",
    "    \n",
    "    # Read CSV data - handle both string and DataFrame inputs\n",
    "    if isinstance(csv_data, pd.DataFrame):\n",
    "        csv_df = csv_data\n",
    "    else:\n",
    "        # Assume it's a string with tab-separated data\n",
    "        csv_df = pd.read_csv(io.StringIO(csv_data), sep='\\t')\n",
    "    \n",
    "    # Prepare comparison results\n",
    "    results = []\n",
    "    \n",
    "    for csv_idx, csv_row in csv_df.iterrows():\n",
    "        csv_filename = str(csv_row.get('Nome file', ''))\n",
    "        csv_full_name = str(csv_row.get('Nominativo', ''))\n",
    "        csv_date = str(csv_row.get('Data', ''))\n",
    "        csv_cluster = str(csv_row.get('Cluster', ''))\n",
    "        \n",
    "        csv_first_name, csv_last_name = extract_name_parts(csv_full_name)\n",
    "        csv_norm_date = normalize_date(csv_date)\n",
    "        \n",
    "        # Count matches for this CSV row\n",
    "        filename_matches = 0\n",
    "        first_name_matches = 0\n",
    "        last_name_matches = 0\n",
    "        date_matches = 0\n",
    "        full_matches = 0\n",
    "        \n",
    "        matching_bat_records = []\n",
    "        \n",
    "        for bat_record in bat_records:\n",
    "            bat_filename = bat_record['filename']\n",
    "            bat_full_name = bat_record['full_name']\n",
    "            bat_date = bat_record['date']\n",
    "            \n",
    "            bat_first_name, bat_last_name = extract_name_parts(bat_full_name)\n",
    "            bat_norm_date = normalize_date(bat_date)\n",
    "            \n",
    "            # Check individual matches\n",
    "            filename_match = csv_filename.lower() == bat_filename.lower() if csv_filename and bat_filename else False\n",
    "            first_name_match = csv_first_name == bat_first_name if csv_first_name and bat_first_name else False\n",
    "            last_name_match = csv_last_name == bat_last_name if csv_last_name and bat_last_name else False\n",
    "            date_match = csv_norm_date == bat_norm_date if csv_norm_date and bat_norm_date else False\n",
    "            \n",
    "            # Count matches\n",
    "            if filename_match:\n",
    "                filename_matches += 1\n",
    "            if first_name_match:\n",
    "                first_name_matches += 1\n",
    "            if last_name_match:\n",
    "                last_name_matches += 1\n",
    "            if date_match:\n",
    "                date_matches += 1\n",
    "            \n",
    "            # Full match: first name, last name, and date all match\n",
    "            if first_name_match and last_name_match and date_match:\n",
    "                full_matches += 1\n",
    "                matching_bat_records.append(f\"{bat_full_name} ({bat_norm_date})\")\n",
    "        \n",
    "        results.append({\n",
    "            'CSV_Row': csv_idx,\n",
    "            'CSV_Filename': csv_filename,\n",
    "            'CSV_Name': csv_full_name,\n",
    "            'CSV_Date': csv_date,\n",
    "            'CSV_Cluster': csv_cluster,\n",
    "            'CSV_First_Name': csv_first_name if csv_first_name else '',\n",
    "            'CSV_Last_Name': csv_last_name if csv_last_name else '',\n",
    "            'CSV_Normalized_Date': csv_norm_date,\n",
    "            'Filename_Matches': filename_matches,\n",
    "            'First_Name_Matches': first_name_matches,\n",
    "            'Last_Name_Matches': last_name_matches,\n",
    "            'Date_Matches': date_matches,\n",
    "            'Full_Matches': full_matches,\n",
    "            'Matching_Records': '; '.join(matching_bat_records) if matching_bat_records else ''\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Calculate overall statistics\n",
    "    total_rows = len(results_df)\n",
    "    total_possible_matches = total_rows * 3  # 3 fields per row: first_name, last_name, date\n",
    "    \n",
    "    # Count actual matches (only count if the field had valid data to match)\n",
    "    actual_first_name_matches = sum(1 for r in results if r['CSV_First_Name'] != '' and r['First_Name_Matches'] > 0)\n",
    "    actual_last_name_matches = sum(1 for r in results if r['CSV_Last_Name'] != '' and r['Last_Name_Matches'] > 0)\n",
    "    actual_date_matches = sum(1 for r in results if r['CSV_Normalized_Date'] != '' and r['Date_Matches'] > 0)\n",
    "    \n",
    "    total_actual_matches = actual_first_name_matches + actual_last_name_matches + actual_date_matches\n",
    "    \n",
    "    # Count valid fields (fields that had data to potentially match)\n",
    "    valid_first_names = sum(1 for r in results if r['CSV_First_Name'] != '')\n",
    "    valid_last_names = sum(1 for r in results if r['CSV_Last_Name'] != '')\n",
    "    valid_dates = sum(1 for r in results if r['CSV_Normalized_Date'] != '')\n",
    "    total_valid_fields = valid_first_names + valid_last_names + valid_dates\n",
    "    \n",
    "    # Add summary statistics to the dataframe as metadata\n",
    "    results_df.attrs['summary'] = {\n",
    "        'total_rows': total_rows,\n",
    "        'total_possible_matches': total_possible_matches,\n",
    "        'total_actual_matches': total_actual_matches,\n",
    "        'total_valid_fields': total_valid_fields,\n",
    "        'match_rate_vs_possible': total_actual_matches / total_possible_matches if total_possible_matches > 0 else 0,\n",
    "        'match_rate_vs_valid': total_actual_matches / total_valid_fields if total_valid_fields > 0 else 0,\n",
    "        'valid_first_names': valid_first_names,\n",
    "        'valid_last_names': valid_last_names,\n",
    "        'valid_dates': valid_dates,\n",
    "        'matched_first_names': actual_first_name_matches,\n",
    "        'matched_last_names': actual_last_name_matches,\n",
    "        'matched_dates': actual_date_matches\n",
    "    }\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def print_match_summary(comparison_results: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Print a summary of the matching statistics\n",
    "    \n",
    "    Args:\n",
    "        comparison_results (pd.DataFrame): Results from compare_dataframes function\n",
    "    \"\"\"\n",
    "    summary = comparison_results.attrs.get('summary', {})\n",
    "    \n",
    "    print(\"=== MATCHING SUMMARY ===\")\n",
    "    print(f\"Total rows analyzed: {summary.get('total_rows', 0)}\")\n",
    "    print(f\"Total possible matches (rows × 3 fields): {summary.get('total_possible_matches', 0)}\")\n",
    "    print(f\"Total actual matches found: {summary.get('total_actual_matches', 0)}\")\n",
    "    print(f\"Total valid fields (with data): {summary.get('total_valid_fields', 0)}\")\n",
    "    print()\n",
    "    print(\"MATCH RATES:\")\n",
    "    print(f\"  Against all possible (matches/rows×3): {summary.get('match_rate_vs_possible', 0):.2%}\")\n",
    "    print(f\"  Against valid fields only: {summary.get('match_rate_vs_valid', 0):.2%}\")\n",
    "    print()\n",
    "    print(\"FIELD BREAKDOWN:\")\n",
    "    print(f\"  First Names: {summary.get('matched_first_names', 0)}/{summary.get('valid_first_names', 0)} matched\")\n",
    "    print(f\"  Last Names: {summary.get('matched_last_names', 0)}/{summary.get('valid_last_names', 0)} matched\")\n",
    "    print(f\"  Dates: {summary.get('matched_dates', 0)}/{summary.get('valid_dates', 0)} matched\")\n",
    "    print()\n",
    "    print(f\"SCORE: {summary.get('total_actual_matches', 0)}/{summary.get('total_possible_matches', 0)} \" +\n",
    "          f\"({summary.get('match_rate_vs_possible', 0):.1%})\")\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Option 1: CSV data from Excel file\n",
    "    csv_data = pd.read_excel('Docs Train.xlsx', engine='openpyxl')  # Changed to .xlsx\n",
    "    \n",
    "    # Compare the dataframes\n",
    "    comparison_results = compare_dataframes('DocumentsOfRecord.dat', csv_data)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print_match_summary(comparison_results)\n",
    "    \n",
    "    # Display detailed results\n",
    "    print(\"\\nDetailed Results:\")\n",
    "    print(comparison_results[['CSV_Name', 'First_Name_Matches', 'Last_Name_Matches', 'Date_Matches', 'Full_Matches']])\n",
    "    \n",
    "    # Option 2: If you have a CSV file instead\n",
    "    # csv_data = pd.read_csv('extracted_data.csv')\n",
    "    # comparison_results = compare_dataframes('your_bat_file.bat', csv_data)\n",
    "    \n",
    "    # Option 3: Original string format still works\n",
    "    # csv_string = \"\"\"Nome file\tCluster\tNominativo\tData\n",
    "    # 0004830357001_2008893.TIF\tNessun cluster\tSassi Maurizio\t18/06/1984\"\"\"\n",
    "    # comparison_results = compare_dataframes('your_bat_file.bat', csv_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
